## high-dimensional clustering에서 발생하는 문제와 해결방안
> 📶 **고차원 데이터 클러스터링 hight-dimensional clustering**
* 차원의 저주 : 차원이 너무 많은 경우, 학습 데이터 수보다 차원의 수가 많아져 성능이 저하되는 문제 발생 가능
* 피쳐 갯수가 늘어날수록 피쳐 간의 상관관계가 발생할 가능성이 높아짐
* 거리 기반 모델(KNN, K-Means 등)의 경우 거리가 왜곡되어 계산될 수 있음
> ✅ **이러한 고차원 데이터의 문제를 해결하고, 유사도 계산 및 클러스터링에 용이하도록 만드려면?**
* 클러스터링 전 차원 축소를 통해 데이터 포인트들 간의 거리가 멀어지지 않도록 방지
  * scree plot을 통해 최적의 차원 수를 찾을 수 있지만 설명력을 고려해 적절한 수 선택이 필요함
* corr()함수, 히트맵 등을 활용해 VIF가 높은 피쳐는 사전에 제거하는 것도 도움이 됨
* 거리 기반 모델을 사용할 때는 차원 축소 후에 사용하는 것이 유리하고, 밀도 기반 모델(DBSCAN, GMM 등)을 사용하는 것도 방법임

## 주성분 분석과 요인 분석의 차이
> ⭐ **주성분 분석 Principal Component Analysis**
* 고차원의 데이터를 저차원으로 환원시키는 기법
* 직교변환을 통해 데이터를 한 개의 축으로 사상시켰을 때 분산이 가장 커지는 축 기준, 순서대로 주성분 지정
> 💡 **주성분 분석과 정준상관분석의 차이점**
  * 주성분 분석 : 하나의 데이터 집합의 변화를 제일 잘 설명하는 새로운 좌표 시스템을 정의 (분산 최대화)
  * 정준상관분석 : 두 개의 데이터 집합간의 교차 공분산을 가장 잘 설명하는 좌표 시스템을 정의 (상관관계 최대화)
> 🔍 **요인 분석 Factor Analysis**
* 변수들 간의 상관관계를 고려하여 저변에 내재된 개념적 요인을 찾아내는 방법
* 입력 변수들 간의 특성을 파악하고, 개념적 요인에 대한 새 피쳐를 생성함으로써 모델의 성능 개선 가능
> 🙌 **차이점**
* 우선, 두 방법 모두 데이터를 축소하여 더 적은 변수로 결과를 설명한다는 점은 같음
1. 변수 간의 서열
   * PCA : 제1주성분, 제2주성분, ... 순으로 변수의 중요도에 따른 서열이 있음
   * FA : 공통적인 특징을 요약해놓은 것이기 때문에 서열이 없음
2. 변수 이름
   * PCA : 제1주성분(PC1), 제2주성분(PC2)과 같은 형식으로 이름이 붙여지므로, 사용자 정의가 불가능함
   * FA : 사용자가 특징을 잘 설명하는 이름을 붙일 수 있음
3. 생성된 변수의 속성
   * PCA : 주성분에 기존의 모든 변수가 영향을 미치고 있음
   * FA : 모든 변수가 공통으로 가지고 있는 특징으로만 묶이고, 개별 변수가 가진 다른 특성까지 완전히 반영되지 않음

## 히스토그램의 주요 단점 및 대안적 시각화 방법




